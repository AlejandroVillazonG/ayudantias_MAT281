{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://matematica.usm.cl/wp-content/themes/dmatUSM/assets/img/logoDMAT2.png\" title=\"Title text\" width= 800 /></center>\n",
    "<hr style=\"height:2px;border:none\"/>\n",
    "<h1 align='center'> Ayudantía 7: Modelos de clasificación, librería scikit-learn</h1>\n",
    "\n",
    "<H3 align='center'> MAT281 2023-2 </H3>\n",
    "\n",
    "<H3 align='center'> Ayud. Alejandro Villazón G. </H3>\n",
    "<hr style=\"height:2px;border:none\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Los modelos de regresión asumen que la variable de respuesta es cuantitativa, sin embargo, en muchas situaciones esta variable es cualitativa/categórica, por ejemplo el color de ojos. La idea de predecir variables categóricas es usualmente nombrada como _Clasificación_. Muchos de los problemas en los que se enfoca el Machine Learning están dentro de esta categoría, por lo mismo como vieron en clases existen una serie de algoritmos y modelos con tal de obtener los mejores resultados. \n",
    "\n",
    "Todos los modelos vistos en clases se encuentran en la librería `sklearn` y la forma de usarlos es muy similar, es por esto que en esta ayudantía introduciremos el algoritmo de clasificación más sencillo: _Regresión Logística_, y uno de los más intuitivos de comprender: _K Nearest Neighbours_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Trabajaremos con el conjunto de datos `Breast Cancer`, donde el objetivo es clasificar, en bases a sus características, si un tumor es Benigno o Maligno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = datasets.load_breast_cancer()\n",
    "breast_cancer = pd.DataFrame(data=data_dict.data,\n",
    "                    columns=data_dict.feature_names)\n",
    "\n",
    "breast_cancer['target'] = data_dict.target\n",
    "\n",
    "breast_cancer.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Scikit-learn` tiene su propia implementación de Regresión Logística, para un enfoque más estadístico te invito a revisar la implementación del paquete `statsmodels`. A medida que vayas leyendo e interiorizándote en la librería verás que tratan de mantener una sintaxis consistente en los distintos objetos y métodos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = breast_cancer.drop('target', axis=1)\n",
    "y = breast_cancer['target']\n",
    "\n",
    "\n",
    "Logit = LogisticRegression(\n",
    "    penalty='l2',\n",
    "    max_iter=10_000\n",
    ")\n",
    "Logit.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos obtener los coeficientes resultantes del ajuste a nuestros datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Logit.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Logit.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos predecir según el modelo entrenado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = Logit.predict(X)\n",
    "y_pred_train[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después de entrenar el modelo, es esencial llevar a cabo una evaluación de desempeño adecuada. Sin embargo, no resulta objetivo evaluar el rendimiento del modelo utilizando los mismos datos que se utilizaron para entrenarlo. Por lo tanto, se hace necesario dividir el conjunto de datos en dos partes: el conjunto de entrenamiento (Train Set) y el conjunto de prueba (Test Set). El Test Set se utiliza exclusivamente para evaluar el rendimiento del modelo final previamente seleccionado, sin involucrarse en la selección de hiperparámetros, como la elección de la norma de penalización, que puede ser $\\ell_1$, $\\ell_2$, o una combinación de ambas.\n",
    "\n",
    "Para ajustar y optimizar los hiperparámetros, se emplea un tercer conjunto llamado Validation Set, que se obtiene al separar una parte del conjunto de entrenamiento. Este conjunto se utiliza para evaluar el desempeño de diferentes modelos comparables que pertenecen a la misma categoría. Por ejemplo, si se busca comparar los siguientes modelos:\n",
    "``` python \n",
    "- LogisticRegression(penalty='l2')\n",
    "```\n",
    "``` python\n",
    "- LogisticRegression(penalty='elasticnet', l1_ratio=0.6)\n",
    "```\n",
    "debemos usar el Validation Set. En cambio, si quiero comparar modelos de diferentes categorías como los siguientes:\n",
    "``` python \n",
    "- LogisticRegression(penalty='l1')\n",
    "```\n",
    "``` python \n",
    "- DecisionTreeClassifier(max_depth=5, min_samples_leaf=10)\n",
    "```\n",
    "debemos usar el Test Set. Es esencial conocer la diferencia entre estos conjuntos de datos, te invito a investigar por tu cuenta [[Articulo]](https://www.geeksforgeeks.org/training-vs-testing-vs-validation-sets/)[[Foro]](https://stats.stackexchange.com/questions/19048/what-is-the-difference-between-test-set-and-validation-set)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entonces dada la discusión anterior, si queremos ver que tan bueno es nuestro modelo, podemos ajustarlo con parte de los datos (Train Set) y ver que tan bueno es (con alguna métrica) con el resto de los datos (Test Set).\n",
    "\n",
    "La siguiente función nos permite separar los datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el proceso de [_hyperparameter tuning_](https://www.geeksforgeeks.org/hyperparameter-tuning/) podemos utilizar la función [`GridSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) de sklearn la que además nos permite realizar Validación Cruzada (lo que nos genera el Validation Set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si queremos buscar los mejores hiperparámetros de un modelo, debemos generar una o más grillas con los valores a tomar por cada hiperparámetro, para que `GridSearchCV` entrene el modelo con todas las combinaciones y luego según una métrica de evaluación entregada por nosotros nos retorne el mejor modelo.\n",
    "\n",
    "Por ejemplo, veamos los hiperparámetros por defecto de una Regresión Logística de sklearn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LogisticRegression().get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    # El nombre de las keys debe ser exactamente el nombre del argumento que recibe el modelo\n",
    "    {'penalty': ['l1', 'l2']},\n",
    "    {'penalty' : ['elasticnet'],\n",
    "     'l1_ratio': [0.2, 0.5, 0.8]\n",
    "    }\n",
    "]\n",
    "\n",
    "logit = LogisticRegression(solver='saga')\n",
    " \n",
    "best_logit = GridSearchCV(logit, param_grid,\n",
    "                          scoring = 'f1',\n",
    "                          cv = 5 # Divisiones del conjunto de entrenamiento para generar conjuntos de Validación\n",
    "                          )\n",
    " \n",
    "best_logit.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtengamos los resultados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_logit.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_logit.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_logit.best_score_ # Promedio del score en las iteraciones del CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También podemos recuperar la historia del entrenamiento, como el score que se obtuvo en cada conjunto de validación al realizar la CV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_logit.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez encontrados los mejores hiperparámetros, se debe entrenar el modelo con todo el conjunto de entrenamiento. Por suerte la función `GridSearchCV` lo realiza por defecto, gracias al parámetro `refit = True`. Por lo que podemos predecir en el Test Set y evaluar el desempeño final del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_logit.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de pasar a la evaluación de desempeño, es prudente recordar que la librería `sklearn` es consistente en su sintaxis, por lo que podriamos cambiar el modelo y de forma análoga podremos realizar la clasificación y sus resultados. A continuación se encuentran todos los modelos vistos en clases:\n",
    "\n",
    "``` python\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import BaggingRegressor, BaggingClassifier, RandomForestClassifier\n",
    "```\n",
    "¡¡Visita la documentación!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Métricas para Clasificación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sabemos que los modelos de clasificación etiquetan a los datos a partir del entrenamiento. Por lo tanto es necesario introducir conceptos vistos en las cátedras.\n",
    "\n",
    "Uno de ellos es la matriz de confusión. Típicamente para un clasificador binario (puede ser extendido fácilmente a un problema multiclase) se tiene:\n",
    "\n",
    "* `TP`: Verdadero Positivo\n",
    "* `FN`: Falso Negativo\n",
    "* `FP`: Falso positivo\n",
    "* `TN`: Verdadero Negativo\n",
    "\n",
    "En este contexto, los valores `TP` y `TN` muestran los valores correctos que tuve al momento de realizar la predicción, mientras que los valores de de `FN` y `FP` denotan los valores en que la clasificación fue errónea.\n",
    "\n",
    "Una manera eficaz de visualizar estos resultados es con la _matriz de confusión_\n",
    "\n",
    "![confusion_matrix](https://miro.medium.com/max/1780/1*LQ1YMKBlbDhH9K6Ujz8QTw.jpeg)\n",
    "\n",
    "En un principio se busca maximizar la suma de los elementos bien clasificados, sin embargo eso depende mucho del problema a resolver. Para esto se definen las siguientes métricas:\n",
    "\n",
    "* Accuracy:\n",
    "\n",
    "    $$\\textrm{accuracy}= \\frac{TP+TN}{TP+TN+FP+FN}$$\n",
    "    \n",
    "* Recall:\n",
    "\n",
    "    $$\\textrm{recall} = \\frac{TP}{TP+FN}$$\n",
    "    \n",
    "* Precision:\n",
    "\n",
    "    $$\\textrm{precision} = \\frac{TP}{TP+FP} $$\n",
    "    \n",
    "* F-score:\n",
    "\n",
    "    $$\\textrm{F-score} = 2\\times \\frac{  \\textrm{precision} \\times \\textrm{recall} }{  \\textrm{precision} + \\textrm{recall} } $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estas son las más comunes, y como te imaginarás, `scikit-learn` tiene toda una artillería de selección de modelos que puedes encontrar en este [enlace](https://scikit-learn.org/stable/modules/model_evaluation.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La forma usual de visualizar el desempeño de un modelo en un problema de clasificación es a través de la matriz de confusión, para esto se presenta dos formas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utiliza el modelo\n",
    "ConfusionMatrixDisplay.from_estimator(\n",
    "    best_logit,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    cmap=plt.cm.Blues,\n",
    "    display_labels=data_dict.target_names,\n",
    "    text_kw={'size':15}\n",
    ")\n",
    "plt.title('Confusion Matrix');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utiliza las predicciones\n",
    "ConfusionMatrixDisplay.from_predictions(\n",
    "    y_test,\n",
    "    y_pred,\n",
    "    cmap=plt.cm.Blues,\n",
    "    display_labels=data_dict.target_names,\n",
    "    text_kw={'size':15}\n",
    ")\n",
    "plt.title('Confusion Matrix');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo no se ajusta perfectamente como es esperado (si no podríamos caer en _overfitting_), pero te puedes basar en los siguientes resultados para hacer un análisis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Accuracy score: {accuracy_score(y_test, y_pred):.3f}\")\n",
    "print(f\"Recall score: {recall_score(y_test, y_pred):.3f}\")\n",
    "print(f\"F1 score: {f1_score(y_test, y_pred):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Incluso podemos generar un reporte mucho más rápido. [Más información](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred, target_names=data_dict.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Curva ROC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para finalizar te presento como graficar la curva ROC presentada en clases, esto nos da otra forma de escoger un buen clasificador.\n",
    "\n",
    "Como casi siempre, `scikit-learn` ya tiene implementada la función y mantiene la sintaxis que usamos al generar la matriz de confusión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import RocCurveDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_disp = RocCurveDisplay.from_estimator(\n",
    "    best_logit, \n",
    "    X_test, \n",
    "    y_test,\n",
    "    name = 'Logit',\n",
    "    c='red'\n",
    ")\n",
    "plt.xlabel('Especificidad'); plt.ylabel('Sensibilidad')\n",
    "plt.title('ROC Curve');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ajustar otros modelos y presentar las curvas en un mismo gráfico!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Esto es solo un ejemplo!\n",
    "rfc = RandomForestClassifier(n_estimators=100, max_depth=2) \n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.gca() # Get Current Axes\n",
    "lda_disp = RocCurveDisplay.from_estimator(lda, X_test, y_test, ax=ax)\n",
    "rfc_disp = RocCurveDisplay.from_estimator(rfc, X_test, y_test, ax=ax)\n",
    "logit_disp.plot(ax=ax)\n",
    "\n",
    "plt.xlabel('Especificidad'); plt.ylabel('Sensibilidad')\n",
    "plt.title('ROC Curves');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos recuperar la AUC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_disp.roc_auc, logit_disp.roc_auc, lda_disp.roc_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con esto llegamos al final de los contenidos, te dejo la invitación a que continues estudiando sobre modelos de aprendizaje automático y fortalezcas tus habilidades de programación, visita la página oficial de [`scikit-learn`](https://scikit-learn.org/stable/index.html), ahí podrás encontrar la documentación de los modelos y tutoriales de todo tipo! \n",
    "\n",
    "También te invito a que investigues temas más avanzados como redes neuronales, para eso visita la página oficial de [`keras`](https://keras.io/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
